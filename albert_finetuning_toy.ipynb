{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune Albert with downstream tasks\n",
    "#### Overview\n",
    "Repo: https://github.com/google-research/ALBERT\n",
    "\n",
    "Refer to run_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import modeling\n",
    "import tokenization\n",
    "import optimization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "MAX_LEN = 50 #95 percentile of validated top relevant text length is 50\n",
    "BATCH_SIZE = 1\n",
    "MAX_GRAD_NORM = 1.0\n",
    "LEARNING_RATE = 0.000001\n",
    "NUM_WARMUP_STEPS= 100\n",
    "OUTPUT_DIR = \"outputs_toy/\"\n",
    "USE_TPU = False\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "label_list = [0,1]\n",
    "init_checkpoint=\"models_toy/\"\n",
    "num_train_steps = 200 \n",
    "run_config = tf.contrib.tpu.RunConfig(model_dir=OUTPUT_DIR,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = modeling.AlbertConfig.from_json_file(\"models_toy/albert_config.json\")\n",
    "tokenizer = tokenization.FullTokenizer.from_scratch(vocab_file=\"models_toy/vocab.txt\", do_lower_case=True, spm_model_file=None)\n",
    "# Test on tokenizer\n",
    "# tokenizer.tokenize(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(file, mode, tokenizer):\n",
    "    df_data = pd.read_csv(file, names = ['text','name'], skiprows =1)\n",
    "    df_data = df_data.dropna()\n",
    "\n",
    "    if ((mode == tf.estimator.ModeKeys.TRAIN)|(mode == tf.estimator.ModeKeys.EVAL)):    \n",
    "        def label_sent(name_tokens, sent_tokens):\n",
    "            label = []\n",
    "            i = 0\n",
    "            if len(name_tokens)>len(sent_tokens):\n",
    "                label = np.zeros(len(sent_tokens))\n",
    "            else:\n",
    "                while i<len(sent_tokens):\n",
    "                    found_match = False\n",
    "                    if name_tokens[0] == sent_tokens[i]:       \n",
    "                        found_match = True\n",
    "                        for j in range(len(name_tokens)-1):\n",
    "                            if ((i+j+1)>=len(sent_tokens)):\n",
    "                                return label\n",
    "                            if name_tokens[j+1] != sent_tokens[i+j+1]:\n",
    "                                found_match = False\n",
    "                        if found_match:\n",
    "                            label.extend(list(np.ones(len(name_tokens)).astype(int)))\n",
    "                            i = i + len(name_tokens)\n",
    "                        else: \n",
    "                            label.extend([0])\n",
    "                            i = i+ 1\n",
    "                    else:\n",
    "                        label.extend([0])\n",
    "                        i=i+1\n",
    "            return label\n",
    "        df_data['text_tokens'] = df_data.text.apply(tokenizer.tokenize)\n",
    "        df_data['text_labels'] = df_data.apply(lambda row: label_sent(row['name'].lower().split(), row['text_tokens']), axis=1)\n",
    "        df_data_sampled = df_data[[np.sum(label)>0 for label in df_data.text_labels]]\n",
    "        input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in df_data_sampled['text_tokens']],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "        labels = pad_sequences(df_data_sampled['text_labels'],\n",
    "                             maxlen=MAX_LEN, padding=\"post\",\n",
    "                             dtype=\"long\", truncating=\"post\")\n",
    "        # create the mask to ignore the padded elements in the sequences.\n",
    "        input_mask = [[int(i>0) for i in ii] for ii in input_ids]\n",
    "        return input_ids, labels, input_mask\n",
    "\n",
    "    else: # Predict \n",
    "        df_data['text_tokens'] = df_data.text.apply(tokenizer.tokenize)\n",
    "        input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in df_data['text_tokens']],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "        # create the mask to ignore the padded elements in the sequences.\n",
    "        input_mask = [[int(i>0) for i in ii] for ii in input_ids]\n",
    "        return input_ids, None, input_mask    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(file, seq_length, drop_remainder, tokenizer):\n",
    "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "\n",
    "    def input_fn(mode, params):\n",
    "        \n",
    "        input_ids, labels, input_mask = process_input(file, mode, tokenizer)\n",
    "    \n",
    "        \"\"\"The actual input function.\"\"\"\n",
    "        batch_size = params[\"batch_size\"]\n",
    "\n",
    "        num_examples = len(input_ids)\n",
    "\n",
    "        # This is for demo purposes and does NOT scale to large data sets. We do\n",
    "        # not use Dataset.from_generator() because that uses tf.py_func which is\n",
    "        # not TPU compatible. The right way to load data is with TFRecordReader.\n",
    "        if ((mode == tf.estimator.ModeKeys.TRAIN)|(mode == tf.estimator.ModeKeys.EVAL)):\n",
    "            d = tf.data.Dataset.from_tensor_slices(\n",
    "                ({\"input_ids\": tf.constant( input_ids, shape=[num_examples, seq_length], dtype=tf.int32),\n",
    "                  \"input_mask\": tf.constant( input_mask, shape=[num_examples, seq_length], dtype=tf.int32),\n",
    "                  \"segment_ids\": tf.zeros(shape=[num_examples, seq_length], dtype=tf.int32),}\n",
    "                 ,tf.constant(labels, shape=[num_examples, seq_length], dtype=tf.int32),))\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                d = d.repeat()\n",
    "                d = d.shuffle(buffer_size=100)\n",
    "\n",
    "            d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "            return d\n",
    "        else: # Predict\n",
    "            d = tf.data.Dataset.from_tensor_slices(\n",
    "                ({\"input_ids\": tf.constant( input_ids, shape=[num_examples, seq_length], dtype=tf.int32),\n",
    "                  \"input_mask\": tf.constant( input_mask, shape=[num_examples, seq_length], dtype=tf.int32),\n",
    "                  \"segment_ids\": tf.zeros(shape=[num_examples, seq_length], dtype=tf.int32),}\n",
    "                 ,tf.zeros(shape=[num_examples, seq_length], dtype=tf.int32),))\n",
    "\n",
    "            d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "            return d        \n",
    "\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(albert_config, mode, input_ids, input_mask, segment_ids,\n",
    "                                 labels, num_labels):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    model = modeling.AlbertModel(\n",
    "            config=albert_config,\n",
    "            is_training=is_training,\n",
    "            input_ids=input_ids,\n",
    "            input_mask=input_mask,\n",
    "            token_type_ids=segment_ids)\n",
    "\n",
    "    output_layer = model.get_sequence_output()\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    output_weight = tf.get_variable(\n",
    "            \"output_weights\", [num_labels, hidden_size],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "            \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "        output_layer = tf.reshape(output_layer, [-1, hidden_size])\n",
    "        logits = tf.matmul(output_layer, output_weight, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        logits = tf.reshape(logits, [-1, MAX_LEN, num_labels])\n",
    "        probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "        predict = tf.argmax(probabilities,axis=-1)        \n",
    "        if ((mode == tf.estimator.ModeKeys.TRAIN)|(mode == tf.estimator.ModeKeys.EVAL)):\n",
    "            log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "            one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "            per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "            loss = tf.reduce_sum(per_example_loss)\n",
    "            return (loss, per_example_loss, logits,predict)\n",
    "        else: # Predict\n",
    "            return (None, None, logits,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(albert_config, num_labels, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps, use_tpu,\n",
    "                     hub_module=None, optimizer=\"adamw\"):\n",
    "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "\n",
    "    def model_fn(features, labels, mode, params):\t# pylint: disable=unused-argument\n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        tf.logging.info(\"*** Features ***\")\n",
    "        for name in sorted(features.keys()):\n",
    "            tf.logging.info(f\"\tname = {name}, shape = {features[name].shape}\")\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = labels\n",
    "\n",
    "        (total_loss, per_example_loss, logits, predictions) = \\\n",
    "                create_model(albert_config, mode, input_ids, input_mask,\n",
    "                                         segment_ids, label_ids, num_labels)\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        initialized_variable_names = {}\n",
    "        scaffold_fn = None\n",
    "        if init_checkpoint:\n",
    "            (assignment_map, initialized_variable_names\n",
    "            ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "            if use_tpu:\n",
    "                def tpu_scaffold():\n",
    "                    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "                    return tf.train.Scaffold()\n",
    "\n",
    "                scaffold_fn = tpu_scaffold\n",
    "            else:\n",
    "                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "\n",
    "        tf.logging.info(\"**** Trainable Variables ****\")\n",
    "        for var in tvars:\n",
    "            init_string = \"\"\n",
    "            if var.name in initialized_variable_names:\n",
    "                init_string = \", *INIT_FROM_CKPT*\"\n",
    "            tf.logging.info(f\"\tname = {var.name}, shape = {var.shape}{init_string}\")\n",
    "\n",
    "        output_spec = None\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\n",
    "            train_op = optimization.create_optimizer(\n",
    "                    total_loss, learning_rate, num_train_steps, num_warmup_steps,\n",
    "                    use_tpu, optimizer)\n",
    "\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                    mode=mode,\n",
    "                    loss=total_loss,\n",
    "                    train_op=train_op,\n",
    "                    scaffold_fn=scaffold_fn)\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            def metric_fn(per_example_loss, label_ids, logits):\n",
    "                predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "                accuracy = tf.metrics.mean(tf.math.equal(label_ids,predictions))\n",
    "                loss = tf.metrics.mean(values=per_example_loss)\n",
    "                #\n",
    "                return {\n",
    "                    \"eval_accuracy\":accuracy,\n",
    "                    \"eval_loss\": loss,\n",
    "                }                \n",
    "            eval_metrics = (metric_fn, [per_example_loss, label_ids, logits])\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                    mode=mode,\n",
    "                    loss=total_loss,\n",
    "                    eval_metrics=eval_metrics,\n",
    "                    scaffold_fn=scaffold_fn)\n",
    "        else: # Predict\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                    mode=mode,\n",
    "                    predictions= predictions,\n",
    "                    scaffold_fn=scaffold_fn)\n",
    "        return output_spec\n",
    "    return model_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x1461742f0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'outputs_toy/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x146230eb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:\tBatch size = 1\n",
      "INFO:tensorflow:\tNum steps = 200\n",
      "WARNING:tensorflow:From /Users/user/anaconda3/envs/albert/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/user/anaconda3/envs/albert/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:\tname = input_ids, shape = (1, 50)\n",
      "INFO:tensorflow:\tname = input_mask, shape = (1, 50)\n",
      "INFO:tensorflow:\tname = segment_ids, shape = (1, 50)\n",
      "WARNING:tensorflow:From /Users/user/GoJek/project_root/ALBERT/modeling.py:252: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /Users/user/anaconda3/envs/albert/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-d2c70630e2f0>:25: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:name bert/embeddings/word_embeddings match to bert/embeddings/word_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/token_type_embeddings match to bert/embeddings/token_type_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/position_embeddings match to bert/embeddings/position_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/LayerNorm/beta match to bert/embeddings/LayerNorm/beta\n",
      "INFO:tensorflow:name bert/embeddings/LayerNorm/gamma match to bert/embeddings/LayerNorm/gamma\n",
      "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/kernel match to bert/encoder/embedding_hidden_mapping_in/kernel\n",
      "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/bias match to bert/encoder/embedding_hidden_mapping_in/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma\n",
      "INFO:tensorflow:name bert/pooler/dense/kernel match to bert/pooler/dense/kernel\n",
      "INFO:tensorflow:name bert/pooler/dense/bias match to bert/pooler/dense/bias\n",
      "INFO:tensorflow:name output_weights does not get matched\n",
      "INFO:tensorflow:name output_bias does not get matched\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:\tname = bert/embeddings/word_embeddings:0, shape = (159, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:\tname = output_bias:0, shape = (2,)\n",
      "INFO:tensorflow:++++++ warmup starts at step 0, for 100 steps ++++++\n",
      "INFO:tensorflow:using adamw\n",
      "WARNING:tensorflow:From /Users/user/anaconda3/envs/albert/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into outputs_toy/model.ckpt.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 9 vs previous value: 9. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 28 vs previous value: 28. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 43 vs previous value: 43. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 49 vs previous value: 49. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 2.04853\n",
      "INFO:tensorflow:examples/sec: 2.04853\n",
      "INFO:tensorflow:global_step/sec: 2.24024\n",
      "INFO:tensorflow:examples/sec: 2.24024\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 112 vs previous value: 112. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 2.19693\n",
      "INFO:tensorflow:examples/sec: 2.19693\n",
      "INFO:tensorflow:Saving checkpoints for 200 into outputs_toy/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00783875.\n",
      "INFO:tensorflow:training_loop marked as finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator at 0x146230f28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ************************TPU setup************************\n",
    "USE_TPU = False\n",
    "# TPU_NAME = \n",
    "# TPU_ZONE = \n",
    "# GCP_PROJECT = \n",
    "# MASTER = \n",
    "# SAVE_CHECKPOINTS_STEPS = \n",
    "# ITERATIONS_PER_LOOP = \n",
    "# NUM_TPU_CORES = \n",
    "\n",
    "# tpu_cluster_resolver = None\n",
    "# if USE_TPU and TPU_NAME:\n",
    "#     tpu_cluster_resolver = contrib_cluster_resolver.TPUClusterResolver(\n",
    "#         TPU_NAME, zone=TPU_ZONE, project=GCP_PROJECT)\n",
    "\n",
    "# is_per_host = contrib_tpu.InputPipelineConfig.PER_HOST_V2\n",
    "# run_config = tf.contrib.tpu.RunConfig(\n",
    "#   cluster=tpu_cluster_resolver,\n",
    "#   master=MASTER,\n",
    "#   model_dir=OUTPUT_DIR,\n",
    "#   save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "#   tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "#       iterations_per_loop=ITERATIONS_PER_LOOP,\n",
    "#       num_shards=NUM_TPU_CORES,\n",
    "#       per_host_input_for_training=is_per_host))\n",
    "\n",
    "# ************************Model & Estimator setup************************\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "        albert_config=config,\n",
    "        num_labels=len(label_list),\n",
    "        init_checkpoint=init_checkpoint,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        num_train_steps=num_train_steps,\n",
    "        num_warmup_steps=NUM_WARMUP_STEPS,\n",
    "        use_tpu=USE_TPU)\n",
    "\n",
    "# If TPU is not available, this will fall back to normal Estimator on CPU\n",
    "# or GPU.\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "        use_tpu=USE_TPU,\n",
    "        model_fn=model_fn,\n",
    "        config=run_config,\n",
    "        train_batch_size=BATCH_SIZE,\n",
    "        eval_batch_size=BATCH_SIZE,\n",
    "        predict_batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>dish_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like the mala steamboat a lot!</td>\n",
       "      <td>mala steamboat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The chicken rice doesn't taste nice.</td>\n",
       "      <td>chicken rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 review       dish_name\n",
       "0      I like the mala steamboat a lot!  mala steamboat\n",
       "1  The chicken rice doesn't taste nice.    chicken rice"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data_toy/dish_name_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.info(\"***** Running training *****\")\n",
    "\n",
    "train_input_fn = input_fn_builder(\n",
    "        file = \"data_toy/dish_name_train.csv\",\n",
    "        tokenizer = tokenizer,\n",
    "        seq_length=MAX_LEN,\n",
    "        drop_remainder=True)\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:\tname = input_ids, shape = (?, 50)\n",
      "INFO:tensorflow:\tname = input_mask, shape = (?, 50)\n",
      "INFO:tensorflow:\tname = segment_ids, shape = (?, 50)\n",
      "INFO:tensorflow:name bert/embeddings/word_embeddings match to bert/embeddings/word_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/token_type_embeddings match to bert/embeddings/token_type_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/position_embeddings match to bert/embeddings/position_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/LayerNorm/beta match to bert/embeddings/LayerNorm/beta\n",
      "INFO:tensorflow:name bert/embeddings/LayerNorm/gamma match to bert/embeddings/LayerNorm/gamma\n",
      "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/kernel match to bert/encoder/embedding_hidden_mapping_in/kernel\n",
      "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/bias match to bert/encoder/embedding_hidden_mapping_in/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma\n",
      "INFO:tensorflow:name bert/pooler/dense/kernel match to bert/pooler/dense/kernel\n",
      "INFO:tensorflow:name bert/pooler/dense/bias match to bert/pooler/dense/bias\n",
      "INFO:tensorflow:name output_weights does not get matched\n",
      "INFO:tensorflow:name output_bias does not get matched\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:\tname = bert/embeddings/word_embeddings:0, shape = (159, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:\tname = output_bias:0, shape = (2,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-29T16:16:36Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outputs_toy/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-29-16:16:37\n",
      "INFO:tensorflow:Saving dict for global step 200: eval_accuracy = 1.0, eval_loss = 0.00089118525, global_step = 200, loss = 0.044559263\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: outputs_toy/model.ckpt-200\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 1.0,\n",
       " 'eval_loss': 0.00089118525,\n",
       " 'loss': 0.044559263,\n",
       " 'global_step': 200}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_input_fn = input_fn_builder(\n",
    "        file = \"data_toy/dish_name_val.csv\",\n",
    "        tokenizer = tokenizer,\n",
    "        seq_length=MAX_LEN,\n",
    "        drop_remainder=False)\n",
    "\n",
    "estimator.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction using validation data from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:\tname = input_ids, shape = (?, 50)\n",
      "INFO:tensorflow:\tname = input_mask, shape = (?, 50)\n",
      "INFO:tensorflow:\tname = segment_ids, shape = (?, 50)\n",
      "INFO:tensorflow:name bert/embeddings/word_embeddings match to bert/embeddings/word_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/token_type_embeddings match to bert/embeddings/token_type_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/position_embeddings match to bert/embeddings/position_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/LayerNorm/beta match to bert/embeddings/LayerNorm/beta\n",
      "INFO:tensorflow:name bert/embeddings/LayerNorm/gamma match to bert/embeddings/LayerNorm/gamma\n",
      "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/kernel match to bert/encoder/embedding_hidden_mapping_in/kernel\n",
      "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/bias match to bert/encoder/embedding_hidden_mapping_in/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma\n",
      "INFO:tensorflow:name bert/pooler/dense/kernel match to bert/pooler/dense/kernel\n",
      "INFO:tensorflow:name bert/pooler/dense/bias match to bert/pooler/dense/bias\n",
      "INFO:tensorflow:name output_weights does not get matched\n",
      "INFO:tensorflow:name output_bias does not get matched\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:\tname = bert/embeddings/word_embeddings:0, shape = (159, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:\tname = output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:\tname = output_bias:0, shape = (2,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outputs_toy/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "predict_input_fn = input_fn_builder(\n",
    "        file = \"data_toy/dish_name_val.csv\",\n",
    "        tokenizer = tokenizer,\n",
    "        seq_length=MAX_LEN,\n",
    "        drop_remainder=False)\n",
    "\n",
    "predictions = []\n",
    "for prediction in estimator.predict(input_fn=predict_input_fn):\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>dish_name</th>\n",
       "      <th>predicted_dish_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like the chicken rice a lot!</td>\n",
       "      <td>chicken rice</td>\n",
       "      <td>chicken rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The mala steamboat doesn't taste nice.</td>\n",
       "      <td>mala steamboat</td>\n",
       "      <td>mala steamboat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   review       dish_name predicted_dish_name\n",
       "0          I like the chicken rice a lot!    chicken rice        chicken rice\n",
       "1  The mala steamboat doesn't taste nice.  mala steamboat      mala steamboat"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predicted_dish_name(predicted_label, tokenized_text):\n",
    "    name_lists = []\n",
    "    if len(np.where(predicted_label>0)[0])>0:\n",
    "        name_idx_combined = np.where(predicted_label>0)[0]\n",
    "        name_idxs = np.split(name_idx_combined, np.where(np.diff(name_idx_combined) != 1)[0]+1)\n",
    "        name_lists.append([\" \".join(np.take(tokenized_text,name_idx)) for name_idx in name_idxs])\n",
    "        # If there duplicate names in the name_lists\n",
    "        name_lists = np.unique(name_lists)[0]\n",
    "        return name_lists\n",
    "    else:\n",
    "        return None\n",
    "df_data_val = pd.read_csv(\"data_toy/dish_name_val.csv\")\n",
    "df_data_val['predicted_dish_name'] = [get_predicted_dish_name(*prediction_token_pair) for prediction_token_pair in \n",
    "                                      zip(predictions, [tokenizer.tokenize(text) for text in df_data_val.review])]\n",
    "df_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "albert",
   "language": "python",
   "name": "albert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
